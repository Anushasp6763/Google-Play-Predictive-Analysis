{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8a35e0-35fa-43b3-b0df-f05fdd6718f9",
   "metadata": {},
   "source": [
    "# Prediction Challenge Part 2: Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f256c-039c-4fb1-9db2-74eb1de3c63d",
   "metadata": {},
   "source": [
    "## How likely is one to download your app?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6583752b-e2fb-4027-81ae-35868bf0e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e99de-bfe2-40bc-bcf9-fdd235d8c85e",
   "metadata": {},
   "source": [
    "### I) Cleaning and Inspecting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af034b12-181d-4a12-acec-7191b3abb649",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'googleplaystore.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k4/8g705c2s0w90v12pxhnz0bqh0000gn/T/ipykernel_39449/475992642.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'googleplaystore.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'googleplaystore.csv'"
     ]
    }
   ],
   "source": [
    "app = pd.read_csv('googleplaystore.csv')\n",
    "app.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e42c77-3d65-4afa-97ee-58397f11f5a4",
   "metadata": {},
   "source": [
    "Getting rid of Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b152b9bc-6368-430f-ad49-c54fa203bb5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/k4/8g705c2s0w90v12pxhnz0bqh0000gn/T/ipykernel_39449/2109413992.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content Rating'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Android Ver'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'app' is not defined"
     ]
    }
   ],
   "source": [
    "app['Rating'].fillna(0, inplace = True)\n",
    "app['Type'].fillna('Unknown', inplace = True)\n",
    "app['Content Rating'].fillna('Unknown', inplace = True)\n",
    "app['Android Ver'].fillna('Unknown', inplace = True)\n",
    "app.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983df92-2a02-4616-90bb-c59447d922a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95bc6d-a15e-43b5-8815-cc6266072fad",
   "metadata": {},
   "source": [
    "#### Rating: Taking a look at the Rating column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec627d43-1a96-4d1a-8a48-8287da921d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app.Rating.dtype)\n",
    "print(app.Rating.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa6d67-5c7a-40dc-a7ab-d343d73c6e3f",
   "metadata": {},
   "source": [
    "#### Reviews: Converting Reviews to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c63848d-c320-4d6c-aafa-ab62d988c1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app.Reviews.dtype)\n",
    "print(app.Reviews.unique())\n",
    "print(app.Reviews.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe211ecf-2dae-49b2-b55f-c937b31ff3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Reviews'] = app['Reviews'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e05da0-4d6b-4771-9e92-324addf0dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_m(value):\n",
    "    if 'M' in value:\n",
    "        return float(value.replace('M', '')) * 1e6\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa36569d-59c4-403a-af21-f7997bd0e7c4",
   "metadata": {},
   "source": [
    "Here M represents million hence converting the M into a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee0ee5-bd07-4180-97dd-d553082802c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Reviews'] = app['Reviews'].apply(converting_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd3d716-7092-4dc4-86ff-b5c0467dcf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Reviews'] = app['Reviews'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d31b5-0348-4dfb-8bbb-6e3f3dc54b88",
   "metadata": {},
   "source": [
    "#### Size: Converting the letters in Size column:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331092fa-c0cb-4af2-a03a-53d209d46345",
   "metadata": {},
   "source": [
    "Doing the same thing as above only with k being kilobyte we convert it to megabyte and remove the letters k and m from the numbers, we also deal with 'Varies with device'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f36fd-8012-4131-9a53-70cc694fdf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_size(size):\n",
    "    if 'k' in size:\n",
    "        return float(size.replace('k', '')) / 1024\n",
    "    elif 'M' in size:\n",
    "        return float(size.replace('M', ''))\n",
    "    elif 'Varies with device' in size:\n",
    "        return np.nan\n",
    "app['Size'] = app['Size'].apply(converting_size)\n",
    "app.rename(columns={'Size' : 'Size(Mb)'}, inplace=True)\n",
    "print(app['Size(Mb)'].dtype)\n",
    "print(app['Size(Mb)'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff567ed-9717-45ea-8390-99e5e5576d0b",
   "metadata": {},
   "source": [
    "#### Installs: Converting the Installs column to numbers only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90361cbe-ca4b-4bf0-a7cf-47f7ce1664f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Installs'] = app['Installs'].apply(lambda x: x.replace('+' , '') if '+' in str(x) else x)\n",
    "app['Installs'] = app['Installs'].apply(lambda x: x.replace(',' , '') if ',' in str(x) else x)\n",
    "app['Installs'] = app['Installs'].apply(lambda x: np.nan if 'Free' in str(x) else x)\n",
    "\n",
    "app['Installs'] = pd.to_numeric(app['Installs'], errors='coerce')\n",
    "\n",
    "print(app['Installs'].dtype)\n",
    "print(app['Installs'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1b5c5-e64a-467f-b41a-d873e062d249",
   "metadata": {},
   "source": [
    "#### Type: Checking Type Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091247c7-2f42-47c5-b148-4c053aa75922",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Type'] = app['Type'].apply(lambda x: np.nan if '0' in str(x) else x)\n",
    "print(app.Type.dtype)\n",
    "print(app.Type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1f5f9-315b-4cb3-af72-7ac00570b36e",
   "metadata": {},
   "source": [
    "#### Price: converting them to float while removing/converting unnecessary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a4c54-09a5-4389-8400-984d9446590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.Price.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f074e2-f703-4944-a05a-14e8c660b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converting_Everyone(val):\n",
    "    if 'Everyone' in val:\n",
    "        return float(val.replace('Everyone', '0'))\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9598c9-5772-4eb3-810e-dba5ad03f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Price'] = app['Price'].apply(converting_Everyone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e4f57-531a-44a6-b01a-801c885d62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Price'] = app['Price'].apply(lambda x: x.replace('$' , '') if '$' in str(x) else x)\n",
    "app['Price'] = app['Price'].apply(lambda x: float(x))\n",
    "app.rename(columns={'Price' : 'Price($)'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d8d4c7-9f6b-42fc-a391-897d482c937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Price($)'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737da0ba-b86c-4925-9c97-b22c1c79b1d6",
   "metadata": {},
   "source": [
    "#### Content Rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a87a29-43d6-4875-8b0a-df192cd1a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app['Content Rating'].dtype)\n",
    "print(app['Content Rating'].unique())\n",
    "print(app['Content Rating'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e5e00e-4a59-46e9-b095-aba55f7c523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Content Rating'] = app['Content Rating'].apply(lambda x: x.replace('Mature 17+' , 'Adults only 18+') if 'Mature 17+' in str(x) else x)\n",
    "print(app['Content Rating'].dtype)\n",
    "print(app['Content Rating'].unique())\n",
    "print(app['Content Rating'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd326f89-bba0-4e99-a303-93c02a7807d6",
   "metadata": {},
   "source": [
    "#### Last Updated Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eeb4d1-81b0-462d-870b-d6a734f446cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app['Last Updated'].dtype)\n",
    "print(app['Last Updated'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cdbbcd-d1fb-4207-9c69-3c627a078ba1",
   "metadata": {},
   "source": [
    "#### Genre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b1339-cfcd-48d8-b58d-1244d4588378",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app['Genres'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9ef636-7c9e-4acb-835c-0e94871bb90c",
   "metadata": {},
   "source": [
    "#### Category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41709af7-2d2b-4cae-b1bf-2978a76be93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbfc932-860c-4d85-bfb2-e34ba884b1f5",
   "metadata": {},
   "source": [
    "Since this data was created 5 years ago and is not updated on a consistent basis, last updated dates do not contributed to my pattern building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750d4816-f4d3-49ed-a01e-69156ac48955",
   "metadata": {},
   "source": [
    "#### Getting the head again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e9d981-c92b-4b92-8a30-fc71d704fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4531609c-b266-4e57-8ad8-945b7ffee7a3",
   "metadata": {},
   "source": [
    "### II) Feature Engineering: Adding more columns based on other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1bff2-af18-4d9c-85a9-f8aa9b4f57c3",
   "metadata": {},
   "source": [
    "#### 1. Applying log transformation to reduce the skewness of Reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853df134-df48-44e4-9e0c-58ef30c52056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a look at reviews:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(app['Reviews'], bins=50)\n",
    "plt.title('Distribution of Reviews')\n",
    "plt.xlabel('Reviews')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "print(app['Reviews'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527fd54-12ea-4ab2-b6c5-325c6bf02caf",
   "metadata": {},
   "source": [
    "The skewness of Reviews is 16.4 which is very high hence we use log transformation to reduce it to avoid biases in data and for better model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3f7d8-9e5f-4e24-b9ba-05a9a4f2ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking a look at reviews:\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(app['Reviews'], bins=50, log = True)\n",
    "plt.title('Distribution of Reviews')\n",
    "plt.xlabel('Reviews')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc85b4-6e13-4616-9b02-de6c828b5d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Log_Reviews'] = np.log(app['Reviews'] + 1)\n",
    "app.head()\n",
    "print(app['Log_Reviews'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f0ce19-32fc-47a6-ab96-32574abd6afe",
   "metadata": {},
   "source": [
    "The skewness is close to 0 as we can see above, hence it is closer to being symmetrical than asymmetrical after log transformation. Therefore we can use it for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3bd1c5-fd70-4d95-a35f-deab61832186",
   "metadata": {},
   "source": [
    "#### 2. Combining Rating and Reviews as it could potentially mean that the app is more likely to be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540e12f-e342-421a-9716-eb1e111373f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app['Rating_Review_Interaction'] = app['Rating'] * app['Log_Reviews']\n",
    "app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5121b1ca-cc0f-4560-9b0d-2ab854336851",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app['Rating_Review_Interaction'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcedaca2-b1ab-4da0-be5a-e7f047d67c0c",
   "metadata": {},
   "source": [
    "From the above skewness we can see that the Rating_Review_Interaction is fairly symmetrical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5c869-4bd4-41e1-a082-1a6657e51f05",
   "metadata": {},
   "source": [
    "A high rating Review interaction number could mean that people loved the app a lot hence they took out time to write a review and to rate, or people did not like the app and they took out time to negatively review and rate. The prior has a higher possibility, as a good rating would fairly mean a good app and combined with high number of reviews would perphaps also indicate a resonably trending app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce792d-1be3-42cc-98d1-413e1cd3a9d1",
   "metadata": {},
   "source": [
    "#### 3. Taking a look at Installs to understand how to categorize them into groups:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5fb42-411f-4bb2-a695-8be74796e8e9",
   "metadata": {},
   "source": [
    "Since installs directly impacts the likeliness to download the app, it is important to include it in a nuanced way in the pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b0771-3e61-4b46-bc1e-6c3eaeef25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(app['Installs'], bins=50, log=True)\n",
    "plt.title('Distribution of Installs')\n",
    "plt.xlabel('Installs')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ed8fe-9c67-431c-b1c1-17c671b8427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying basic statistics\n",
    "print(app['Installs'].describe())\n",
    "print(app['Installs'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d6ea1-2899-4d4a-a6b9-4ab762484f10",
   "metadata": {},
   "source": [
    "Due to high skewness we may think to take a Threshold to be 75% considering the popular apps which would focus on the top 25% of apps by installs, resulting in a meaningful distinction between high and low likelihood for downloads\n",
    "\n",
    "Since people will be more attracted when the number of downloads are high hence, taking only the top 25% will help in pattern may be a better idea considering highly skewed number of Installs, allowing me to focus on a subset of apps that are most relevant to the characteristics of highly likely download.\n",
    "\n",
    "Making the pattern more complex we take another condition in deciciding, the Rating > 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9add2d8-cebe-4166-9a28-63375909289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5_000_000  # 5 million installs\n",
    "app['High Number of Installs(more than 5M and rating>=4.5)'] = ((app['Installs'] >= threshold) & (app['Rating'] >= 4.5)).astype(int)\n",
    "app.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5e6fa-999d-4292-8a9a-7aec486ed1b6",
   "metadata": {},
   "source": [
    "#### 4. Using Size in our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93b974-af89-4769-b990-eedff6f2f3bb",
   "metadata": {},
   "source": [
    "Another very relevant feature is Size. With good rating, reviews, it is important that the app is of reasonable size. Therefore, including size in the pattern is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b3c37-f1ac-4357-961e-7c5bbe716731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying basic statistics\n",
    "print(app['Size(Mb)'].describe())\n",
    "print(app['Size(Mb)'].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dda838-9c06-408a-b731-2ed2eae69188",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(app['Size(Mb)'], bins=50)\n",
    "plt.title('Distribution of Size(Mb)')\n",
    "plt.xlabel('Size(Mb)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c3703f-4995-491d-befe-6bc021dbe11e",
   "metadata": {},
   "source": [
    "As we can see that Size as well is skewed hence we can use log transformation as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02437dc6-0e96-4b30-a955-bdc6fa664021",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(app['Size(Mb)'], bins=50, log=True)\n",
    "plt.title('Distribution of Size(Mb)')\n",
    "plt.xlabel('Size(Mb)')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5780790d-1665-44b1-88f3-36107e9d2874",
   "metadata": {},
   "source": [
    "Similar to what we did for installs, but here we take the threshold as the value of the 75% and below. Hence, we include apps that have size less than 30mb and to make the pattern more complex we take another condition in deciciding as above, the Rating > 3 which is a resonable rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d944e-4843-4335-b106-15f8db912036",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 30 \n",
    "app['Size(<=30andrating>3)'] = ((app['Size(Mb)'] < threshold) & (app['Rating'] >= 3)).astype(int)\n",
    "app.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5213a8a-ea97-4ffe-9377-7369c1bdc417",
   "metadata": {},
   "source": [
    "#### 5. Getting Composite Score!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3233493b-f834-4682-ab55-10d682affc23",
   "metadata": {},
   "source": [
    "To create a more impactful pattern, a composite score may come in handy therefore, I created one based on a four important columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95289e-7128-4014-9d1e-e588b9dd4a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights for each componenet\n",
    "RatingWeight = 1\n",
    "RatingReviewInteractionWeight = 2\n",
    "LogSizeWeight = 2\n",
    "priceweight = 0.5\n",
    "installsweight = 1.5\n",
    "# Calculate the composite score\n",
    "app['Composite_Score'] = ((RatingWeight * app['Rating']) +\n",
    "    (RatingReviewInteractionWeight * app['Rating_Review_Interaction']) -\n",
    "    (LogSizeWeight * app['Size(<=30andrating>3)']) + (installsweight* app['High Number of Installs(more than 5M and rating>=4.5)']))\n",
    "\n",
    "app.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd4245f-2f65-4015-975c-ecb994cd8043",
   "metadata": {},
   "source": [
    "We want high rating hence we have a good weight for Rating. We also want a high rating and review interaction value hance we + to the composite score, with again a good weight. Coming to the size, we want less size and it is important as people with low storage may struggle. Then we also want a low size and finally high number of installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8608fb-c045-443a-b600-46e03ed3feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(app['Composite_Score'].describe())\n",
    "print(app['Composite_Score'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73a04b2-a04f-477a-afcc-45fc0026137a",
   "metadata": {},
   "source": [
    "### III) Dealing with NaNs and missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a46ac5-8200-4688-ac98-f2ffd04e83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in app.columns:\n",
    "    if app[column].dtype in ['int64', 'float64']:\n",
    "        median = app[column].median()\n",
    "        app[column].fillna(median, inplace=True)\n",
    "    else:\n",
    "        mode = app[column].mode()[0]  \n",
    "        app[column].fillna(mode, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39598165-6f1d-42ef-8edb-00fed4424146",
   "metadata": {},
   "source": [
    "### IV) Creating the Target Column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd33522-337f-4097-bba7-840e5983adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_review_interaction = app['Rating_Review_Interaction'].quantile(0.75) #Have high rating-review interaction\n",
    "median_rating_review_interaction = app['Rating_Review_Interaction'].quantile(0.5)#Have above medium rating review interaction\n",
    "low_rating_review_interaction = app['Rating_Review_Interaction'].quantile(0.25)\n",
    "# Calculate size thresholds: excessively large, under the assumption that very large apps might be less likely to be downloaded due to storage and data constraints. \n",
    "  # Median\n",
    "def Likely_to_Download(row):\n",
    "    if (row['Type'] == 'Free' and\n",
    "        row['Rating_Review_Interaction'] > rating_review_interaction and\n",
    "        row['Category'] in ['FAMILY','GAME', 'BUSINESS', 'MEDICAL', 'TOOLS'] and \n",
    "        row['Content Rating'] == 'Everyone' and\n",
    "        row['Composite_Score'] > 100 and\n",
    "        row['Size(<=30andrating>3)'] == 1 and\n",
    "        row['High Number of Installs(more than 5M and rating>=4.5)'] == 1):\n",
    "        return 'Highly Likely'\n",
    "    elif (row['Type'] == 'Free' and\n",
    "          row['Rating_Review_Interaction'] > median_rating_review_interaction and\n",
    "          row['Size(<=30andrating>3)'] == 0 and\n",
    "          row['High Number of Installs(more than 5M and rating>=4.5)'] == 0):\n",
    "        return 'Likely'\n",
    "    elif (row['Rating_Review_Interaction'] > low_rating_review_interaction):\n",
    "        return 'Not Likely'\n",
    "    else:\n",
    "        return 'Disregard'\n",
    "app['Likely to be Downloaded'] = app.apply(Likely_to_Download, axis=1)\n",
    "app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e961a479-1bd9-413d-af80-6bbfc8185782",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/anushaparanjpe/Downloads/PredictionChallenge/modified_googleapp_dataset.csv'\n",
    "app.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4090d-3ec8-493d-af2f-63b222aecb71",
   "metadata": {},
   "source": [
    "In the highly Likely:\n",
    "\n",
    "The apps should be free\n",
    "The Rating_Review Interaction should be high\n",
    "In Category, 'FAMILY','GAME', 'BUSINESS', 'MEDICAL', 'TOOLS' are some of the top ones hence more apps from these categories are likely to be downloaded.\n",
    "Content Rating: Everyone, 'Everyone' has the most count and most likely to be a part of highly likely downloads.\n",
    "Composite Score > 100 as we can 75% 97.044412 hence it is a resonable approach\n",
    "row['Size(<=30andrating>3)'] == 1 is understood as less than 30 mb and rating greater than 3\n",
    "'High Number of Installs(more than 5M and rating>=4.5)'] == 1) can be understood as well as more people are drawn when there are higher number of installs. In a similar fashion the Likely attribute was made and lastly the rest would be Not Likely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f20023-c070-47be-b289-07e821a27cb3",
   "metadata": {},
   "source": [
    "#### Taking a look at all the highly likely rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3561de9d-c978-4626-b0ba-011bff3a337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.groupby('Likely to be Downloaded').get_group('Highly Likely')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5908018-4af2-44a2-b7ff-7444098e9a64",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------\n",
    "---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f8be03-46df-4040-85e8-828fa131e170",
   "metadata": {},
   "source": [
    "### Hypothetical Situation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95114d5-ef01-4829-b6d6-20ed80833893",
   "metadata": {},
   "source": [
    "##### Coming to the hypothetical Sitatuation where a Student tries to build a model using this dataset to predict the response variable: Likely to be Downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3051a-bffa-47c4-879c-d6896ca635a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the dataset after cleaning:\n",
    "student_data = app.drop(['Log_Reviews','Rating_Review_Interaction','High Number of Installs(more than 5M and rating>=4.5)','Size(<=30andrating>3)','Composite_Score'], axis = 1)\n",
    "print(student_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe5979-aee3-45e8-b63e-38c73a3d8fca",
   "metadata": {},
   "source": [
    "Looking at the missing values, the student would first think to deal with them in order to create a successful model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a71904-93ea-43c2-9f67-bc71f6434f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9fae0d-05cd-45da-9426-31a0ebe0371b",
   "metadata": {},
   "source": [
    "Looking at the columns the student may resonably think that columns like Unnamed, App, Last Updated may not be of relevence, as the dataset is 5 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9048b-9c23-4b16-b9b1-33638b82f2cf",
   "metadata": {},
   "source": [
    "#### Now to inspect the columns and think which columns would impact the the response column:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9953395e-3657-4324-b51e-7305f1e22540",
   "metadata": {},
   "source": [
    "1. The student may start with visualizations as they help the most in understanding the dataset: The most relevant columns to the likeliness of downloading an app would be the Reviews, the Ratings, number of installs and perhaps the Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e19869-0455-4d0d-953d-4bd50b569d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "##Getting the histogram of each of the columns mentioned above: 'Rating', 'Reviews', 'Price', 'Installs'\n",
    "fig, ax = plt.subplots(1, 5, figsize=(18, 6))\n",
    "sns.histplot(student_data['Rating'].dropna(), bins=20, kde=True, ax=ax[0])\n",
    "ax[0].set_title('Ratings Distribution')\n",
    "\n",
    "sns.histplot(student_data['Reviews'], bins=20, kde=True, ax=ax[1])\n",
    "ax[1].set_title('Reviews Distribution')\n",
    "\n",
    "sns.histplot(student_data['Price($)'].dropna(), bins=20, kde=True, ax=ax[2])\n",
    "ax[2].set_title('Price Distribution')\n",
    "\n",
    "sns.histplot(student_data['Installs'].dropna(), bins=20, kde=True, ax=ax[3])\n",
    "ax[3].set_title('Installs Distribution')\n",
    "\n",
    "sns.histplot(student_data['Size(Mb)'].dropna(), bins=20, kde=True, ax=ax[4])\n",
    "ax[4].set_title('Size(Mb) Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa5fc8-69a9-4552-bd20-bf0496161a60",
   "metadata": {},
   "source": [
    "#### From the above plots it may hint the student that the columns Reviews, Price and Installs are highly skewed. Hence, the student may attempt to individually check these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768eadf7-f729-4629-9328-be38d6e4a4de",
   "metadata": {},
   "source": [
    "i) Reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3cae4a-7434-434b-96ce-0ac6492e50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_data['Reviews'].describe())\n",
    "print(student_data['Reviews'].skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5c811-07bc-4181-ae1c-5a3df0a4c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data['Log_Reviews'] = np.log(student_data['Reviews'] + 1)\n",
    "print(student_data['Log_Reviews'].skew())\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5f3f0-abaa-431e-a7e7-813257505339",
   "metadata": {},
   "source": [
    "ii) Price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c36e2cf-d193-48d2-9f50-4e60781b6345",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_data['Price($)'].describe())\n",
    "print(student_data['Price($)'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aaa408-dbcc-4b16-a06b-57de5566415a",
   "metadata": {},
   "source": [
    "The above value of skewness is very high and portrays the following:\n",
    "\n",
    "1. 75% of the observations have values of 0 or higher indicating that a large amount of the dataset consists of zeros.\n",
    "\n",
    "2. The value at max is 400, highlighting the presence of extreme values or outliers that affect the mean and the standard deviation.\n",
    "\n",
    "Hence using the price column does not sound reasonable.\n",
    "\n",
    "Therefore, instead of Price the student may use the Type column for modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3923371a-fd14-4364-b8a6-2f476993a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data['Free_apps'] = student_data['Type'].apply(lambda x: 1 if x == 'Free' else 0)\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541c92f-7ad0-4e61-ace5-afcdcbed30cb",
   "metadata": {},
   "source": [
    "iii) Installs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799c53d6-d9b5-406e-8fe9-ba4380aea7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_data['Installs'].describe())\n",
    "print(student_data['Installs'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaeaf90-5388-4dc1-8221-fba20ecec2f9",
   "metadata": {},
   "source": [
    "Through this it can be seen that 75 percent of the data in Installs column has values 5M or higher. But with this information it may not come to the student's mind to create a column based on this in order to get the top 25 percent or the popular apps. Although it may clue the student to by seeing the number at 75%.\n",
    "\n",
    "The student may set a general threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e899ceb-418f-4bcf-ab71-b49450fdc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data['High Number of Installs'] = (student_data['Installs'] > 1e6).astype(int)\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1184ef-d45f-46d8-b488-adf605d22848",
   "metadata": {},
   "source": [
    "iv) Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933c736-a326-4043-95ce-1f8967756c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_data['Size(Mb)'].describe())\n",
    "print(student_data['Size(Mb)'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a687962-d34e-4279-bc6c-d8659d8a6253",
   "metadata": {},
   "source": [
    "The student may apply log transformation to Size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1008a3-5cd5-4931-9f0c-67860cc9ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data['Log_Size(Mb)'] = np.log(student_data['Size(Mb)'] + 1)\n",
    "print(student_data['Log_Size(Mb)'].skew())\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b04980-d611-4f50-8670-4e8b0105de3e",
   "metadata": {},
   "source": [
    "Now the skewness is very low hence it can be used of modeling\n",
    "\n",
    "#### With this current information the student may start creating models:\n",
    "\n",
    "Getting the data ready to create models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81f7cb-cfc6-4b59-a9f2-f9f37539d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Features and Target variable\n",
    "X = pd.get_dummies(student_data.drop(columns=['Likely to be Downloaded', 'App', 'Category',  'Content Rating', 'Genres', 'Last Updated']),drop_first=True)#dropping the target variable and using one hot encoding\n",
    "y = student_data['Likely to be Downloaded']\n",
    "y = le.fit_transform(y)\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a8ce4-5572-4951-b702-8b818c7bd1cf",
   "metadata": {},
   "source": [
    "#### Model 1: Using Logistic Regression: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049ba41-47f4-4192-91e1-bcb993cf053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "log_reg_accuracy = accuracy_score(y_test, y_pred)\n",
    "log_reg_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "\n",
    "log_reg_accuracy, log_reg_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805bb3d-505e-452b-b0a2-4efa558accb5",
   "metadata": {},
   "source": [
    "#### Model 2: Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26af05f-fa4c-4a42-b734-c4dd3846a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "#X_train_filled = np.nan_to_num(X_train_scaled, nan=np.nanmedian(X_train_scaled, axis=0))\n",
    "#X_test_filled = np.nan_to_num(X_test_scaled, nan=np.nanmedian(X_test_scaled, axis=0))\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating the model\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf, average = 'macro')\n",
    "\n",
    "rf_accuracy, rf_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bc0d5-65b5-4caf-8c74-39ce2ee67417",
   "metadata": {},
   "source": [
    "#### Therefore, if the student is able to find the key points of skewness and log transformations, it is possible to get a good prediction using random forest model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
